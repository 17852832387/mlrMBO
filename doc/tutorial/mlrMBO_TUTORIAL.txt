Introduction
============

**mlrMBO** is a framework for the (sequential) Model Based parameter Optimization.
The goal is to optimize numeric or discrete influence parameters
of a non-linear black box function like an industrial simulator or  a time-consuming algorithm. 

The first step of MBO requires an initial set of evaluation points which is then evaluated by the black box function.  
The basic procedure of MBO is an iterating loop of the following steps: 
Firstly, a user defined surrogate model is fitted on the evaluated points, secondly, a new evaluation point is proposed 
by an infill criterion and lastly, its performance is evaluated.
The result of this sequential procedure is the optimization path containing the best
parameter setting and the fitted surrogate model.

The main function of the package **mlrMBO** is ``mbo()´´
containing following essential parameters:

* fun	     Fitness function to minimize.
* par.set	 Description of the parameter set
* design	 Initial design.
* learner	 Surrogate model type.
* control	 MBOControl object.
* show.info  A logical value. Default is TRUE: show output on console.


This web page will provide you with an in-depth introduction on how to
set the ``mbo()´´ parameters depending on the desired kind of optimization.

Our focus is on your comprehension of the basic functions and
applications. For detailed technical information and manual pages, please refer to
the package's [manual pages](http://berndbischl.github.io/mlrMBO/man/).
They are regularly updated and reflect the documentation
of the current packages on CRAN.



Objective Function
=====================

The first argument of ``mbo()`` is the name of the object function to minimize. The first argument of this object function has to be a list of values.
The function has to return a single numerical value. We demonstrate in this tutorial optimization of two simple functions: 5 dimensional ``ackley function`` from
package **soobench** (``objfun1``) and a self-constructed sine und cosine combination (``objfun2``). ``objfun1`` depends on 5 numeric parameters 
while ``objfun2`` assumes 2 numeric and 1 discrete parameters (s. [Parameter Set](http://berndbischl.github.io/mlrMBO/man/Parameter Set.html)).

```{r}
library(soobench)
objfun1=generate_ackley_function(dimensions=5)
objfun2=function(listOfValues)
{
  x=listOfValues[[1]]
  k=listOfValues[[2]]
  method=listOfValues[[3]]
  perf= ifelse(listOfValues[[3]]=="a", k*sin(x)+cos(x),
               sin(x)+k*cos(x))
  return(perf)
}
```


We aim to maximize ``objfun2``.  Section [MBOControl](link) shows how to set the MBOControl object in order to switch the maximization problem into a minimization one. 

Parameter set
=============

The second argument of ``mbo()`` function, ``par.set``,  has to be a ParamSet object from **ParamHelpers** package, which provides information about parameters
of the [Objective Function](http://berndbischl.github.io/mlrMBO/man/ObjectiveFunction.html) and their constraints for optimization.
The lower and upper bounds for ``objfun1`` parameters can be easily obtained using **soobench** function ``lower_bounds``. For ``objfun2`` we 
assume ``x`` from interval [0,1] and ``k`` from interval [1,2]. Parameter ``method`` can be either ``"a"`` or ``"b"``.

```{r}
library(ParamHelpers)
par.set1 = makeNumericParamSet(len = number_of_parameters(objfun1), lower = lower_bounds(objfun1), upper = upper_bounds(objfun1))
par.set2=makeParamSet(
  makeNumericParam("x", lower=0,upper=1),
  makeIntegerParam("k", lower=1, upper=2),
  makeDiscreteParam("method", values=c("a", "b"))
)
```


Initial Design
==============
The third argument of ``mbo()`` function is the initial design ``design`` with default setting ``NULL``.
Users have two options for initial design defining:
either to create itself a design und assign the ``design`` parameter with it or
to provide settings for design generation in the [MBOControl](http://berndbischl.github.io/mlrMBO/man/MBOControl.html) object.

In the first case it is recommendable to use ``generateDesign`` function from **ParamHelpers** package.
However, if special designs are desired (e.g., orthogonal designs), its interface
has to be the same as the interface of the ``generateDesign`` objects. Particular attention has to be paid to the setting of the ``trafo`` attribute.

In the second case following parameters of ``makeMBOControl`` function which returns [MBOControl] object
are relevant:
 * ``init.design.points``: Initial design size, default setting is 20.
 * ``init.design.fun``: Any function from **lhs** package, default is ``maximinLHS``.
 * ``init.design.args``:  List of further arguments passed to ``init.design.fun``, default is empty list.

Here we will use the first option for ``objfun1`` and the second option for ``objfun2``. In the both cases we will generate an initial design of size 
5*(dimension of the object function).
 
 
 ```{r}
library(lhs)
init.design.points1=5*sum(getParamLengths(par.set1))
init.design.fun1=randomLHS
set.seed(1)
design1=generateDesign(n=init.design.points1, par.set=par.set1, fun=init.design.fun1, trafo=FALSE)

# will be used later as makeMBOControl()  arguments
init.design.points2=5*sum(getParamLengths(par.set2))
init.design.fun2=maximinLHS
init.design.args2=list(k=3,dup=4)
```
 
 
Surrogate Model
==============
Attribute ``learner`` of the ``mbo()`` function allows us to choose an appropriate surrogate model for the parameter optimization.
It can be easily done using the ``makeLearner`` function from **mlr** package. 
List of implemented learners can be seen using ?learners command. [Here an appropriate link]. The choice of the surrogate model depends on the parameters 
of the objective function. While kriging models are advisable for the numeric parameters, random forest models can be used if at least one parameter is discrete.
In our example we consider these two surrogate models:
``kriging`` for optimizing of ``objfun1``  and ``random forest`` for ``objfun2``.

```{r}
library(mlr)
learner_km=makeLearner("regr.km", predict.type="se", covtype="matern3_2")
learner_rf=makeLearner("regr.randomForest")
```

MBOControl
==========
Subsequently user can change the default settings of the ``mboControl`` [zitat] object
using ``makeMBOControl`` function, in order to configure the ``mbo`` in the desired
way. Settings regarding the initial design were already mentioned in [Initial Design](link)

Attribute ``infill.crit``
-------------------------
One of the most important issues is to define how the next design points in
the sequential loops have to be chosen. Firstly, we have to choose the infill criterion using the  ``infill.crit`` attribute. 
At the moment four possibilities are implemented: 
* ``mean``: mean response of the surrogate model, 
* ``ei``: expected improvement of the surrogate model,
* ``aei``: augmented expected improvement, as designed by [Zitat_Huang](link), is specially useful for the noisy functions,
* ``lcb``: lower confidence bound which is the additive combination of mean response and mean standard error estimation 
of the surrogate model (response - lambda * standard.error) [Paper_Zitat](link). The default value of lambda is 1, but it can be easily changed by
the ``infill.crit.lcb`` attribute. This setting is especially useful for the noisy functions.


Attribute ``infill.opt.fun``
--------------------------

[Dieser Abschnitt soll stark verbessert werden] 
Expected Improvement (EI) was originally proposed for kriging models and combines in a certain way mean model prediction and model uncertainty. 
We expanded the idea of EI to any other model by computing the model uncertainty through the bootstrap - uncertainty estimator (???).
FIXME: ?Do we use DiceOptim?

The attribute ``infill.opt.fun`` sets how the next point to evaluate should be proposed given an infill criterion: ``focus``, ``cmaes`` or ``ea``. 

[Hier ersetzen durch focus.search]
In the first case a large sequential design is sampled in the
parameter space (by ``randomLHS`` function) and the surrogate model is used to predict the infill criterion in each point of this design. 
The next point to evaluate is then a point with the best infill criterion value. User can set the size of the sequential design 
by ``infill.opt.random.points`` attribute (default is 10000). 


If ``infill.opt.fun`` is ``cmaes``, the point, which optimizes the
infill criterion, is chosen via ``cma_es`` function of  **cmaes** package. Control argument for cmaes optimizer can be provided in 
``infill.opt.cmaes.control`` attribute (default is empty list).

If ``infill.opt.fun`` is ``ea`` .... [vervollständigen]


Further attributes 
------------------

The number of sequential steps (iterations) can be set in attribute ``iters`` (default setting 10). 
Furthermore, user can specify whether the function have to be minimized or maximized in attribute ``minimize`` (default setting TRUE , e.g.,  minimization). 



Constructing  of ``mboControl`` object
------------------

Let us construct ``mboControl`` objects for our two object functions.

```{r}
control1 = makeMBOControl(
  iters = 20, 
  infill.crit="ei",
  infill.opt="cmaes")


control2 = makeMBOControl(
  minimize=FALSE,
  iters = 20, 
  infill.crit="mean",
  infill.opt="focus.search",
  init.design.points=init.design.points2,
  init.design.fun=init.design.fun2,
  init.design.args=init.design.args2)
```

Experiments and Output
======================

Now we will apply the mbo() function to optimize the both objective functions

As the first argument of the objectiv function has to be a list of values and for the
objfun1 it is two-dementional numeric vector, we wrapp objfun1 with makeMBOFunction() function
which was created extra for this purpose.


```
library(mlrMBO)
library(BBmisc)

mbo1=mbo(makeMBOFunction(objfun1), par.set1, design=design1, learner=learner_km, control=control1, show.info=TRUE)
```{r}







Does not work at the moment!











